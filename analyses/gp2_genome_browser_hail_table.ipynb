{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "### Check environment requirements\n",
    "\n",
    "**IMPORTANT!** This notebook has special environment requirements. Makes sure to install Hail (https://hail.is/docs/0.2/index.html) and run on Google Dataproc clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "# General use and data science packages\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Hail-specific packages\n",
    "import hail as hl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Hail session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Hail engine\n",
    "hl.init(log = 'ces.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical-exome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load meta data to hail\n",
    "\n",
    "ces_meta = hl.import_table(f'{bucket}/pf-exome-broswer/PDGENE_full_data_label.txt',\n",
    "key='s',\n",
    "impute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique ancestry\n",
    "labels=ces_meta.pop.collect()\n",
    "ancestry = list(dict.fromkeys(labels))\n",
    "ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ancestry count\n",
    "print(f'Count for ancestry : {meta.aggregate(hl.agg.counter(ces_meta.pop))}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the import function on the GCS file path\n",
    "\n",
    "mt = hl.import_vcf(f'{bucket}/pf-exome-broswer/all_chrs.vcf.gz',reference_genome='GRCh38', force_bgz=True)\n",
    "\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare variant annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split CSQ to array that we can choose\n",
    "mt = mt.annotate_rows(csq_array = mt.info.CSQ.map(lambda x: x.split('\\|'))[0])\n",
    "#keep the field we want\n",
    "# Find the index of 'SYMBOL'\n",
    "consequence = CSQ.index(\"Consequence\")\n",
    "gene_id = CSQ.index(\"Gene\")\n",
    "transcript_id = CSQ.index(\"Feature\")\n",
    "gene_name = CSQ.index(\"SYMBOL\")\n",
    "hgvsc = CSQ.index(\"HGVSc\")\n",
    "hgvsp = CSQ.index(\"HGVSp\")\n",
    "cadd = CSQ.index(\"CADD_PHRED\")\n",
    "\n",
    "mt = mt.annotate_rows(consequence = mt.csq_array[consequence],\n",
    "                                gene_id = mt.csq_array[gene_id],\n",
    "                                transcript_id = mt.csq_array[transcript_id],\n",
    "                                gene_name = mt.csq_array[gene_name],\n",
    "                                hgvsc = mt.csq_array[hgvsc],\n",
    "                                hgvsp = mt.csq_array[hgvsp],\n",
    "                                cadd = mt.csq_array[cadd]\n",
    "                               )\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update all the '' to be NaN\n",
    "mt= mt.annotate_rows(hgvsp = hl.if_else(mt.hgvsp!=\"\", mt.hgvsp, hl.missing('str')),\n",
    "                     hgvsc = hl.if_else(mt.hgvsc!=\"\", mt.hgvsc, hl.missing('str')),\n",
    "                     gene_name = hl.if_else(mt.gene_name!=\"\", mt.gene_name, hl.missing('str')),\n",
    "                     cadd = hl.if_else(mt.cadd!=\"\", mt.cadd, hl.missing('str'))         \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.select_rows(variant_id = mt.rsid,\n",
    "                    gene_id = mt.gene_id,\n",
    "                    transcript_id = mt.transcript_id,\n",
    "                    consequence = mt.consequence,\n",
    "                    gene_name = mt.gene_name,\n",
    "                    hgvsc = mt.hgvsc,\n",
    "                    hgvsp = mt.hgvsp,\n",
    "                    cadd = mt.cadd                                 \n",
    "                    )\n",
    "\n",
    "# keep just the row fields and filter out gene_id w/o gene_name \n",
    "# filter out intergenic_variant\n",
    "# change cadd to float64 \n",
    "ces_anno_ht = mt.rows()\n",
    "ces_anno_ht = ces_anno_ht.filter((ces_anno_ht.gene_id != '') & (ces_anno_ht.consequence != 'intergenic_variant'))\n",
    "\n",
    "# change cadd to float64 \n",
    "ces_anno_ht = ces_anno_ht.annotate(cadd = hl.float(ces_anno_ht.cadd))\n",
    "\n",
    "ces_anno_ht.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ces_anno_ht = ces_anno_ht.annotate(hgvsp = ces_anno_ht.hgvsp.replace(\"%3D\", \"=\"))\n",
    "ces_anno_ht = ces_anno_ht.annotate(variant_id = ces_anno_ht.variant_id.replace(\"_\", \":\"))\n",
    "\n",
    "ces_anno_ht.filter(hl.is_defined(ces_anno_ht.hgvsp)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out variant annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out \n",
    "ces_anno_ht.write(f'{out_path}/browser_variant_annotation_table.ht', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Variant results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(**ces_meta[mt.s])\n",
    "\n",
    "mt.col.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove CES that are dup of WGS\n",
    "s_to_rm = hl.import_table(f'{bucket}/pf-exome-broswer/ces_to_remove_dup.txt',\n",
    "key='s',\n",
    "impute=True)\n",
    "\n",
    "s_to_rm.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove CES that are dup of WGS\n",
    "mt = mt.filter_cols(hl.is_defined(s_to_rm[mt.s]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ancestry\n",
    "\n",
    "lables=mt.pop.collect()\n",
    "ancestry = list(dict.fromkeys(lables))\n",
    "ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_stats_expression = []\n",
    "\n",
    "for group in ancestry:\n",
    "    call_stats_expression.append(\n",
    "        hl.struct(ancestry=group,\n",
    "                  dataset= 'CES',\n",
    "                  case=hl.agg.filter(\n",
    "                        (mt.pop==group) & (mt.pheno=='Case'), \n",
    "                        hl.agg.call_stats(mt.GT, mt.alleles)), \n",
    "                  ctrl=hl.agg.filter(\n",
    "                        (mt.pop==group) & (mt.pheno=='Control'), \n",
    "                        hl.agg.call_stats(mt.GT, mt.alleles)))\n",
    ")\n",
    "    \n",
    "mt_freq = mt.annotate_rows(explode_data=call_stats_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to explode\n",
    "\n",
    "mt_freq = mt_freq.explode_rows('explode_data')\n",
    "mt_freq = mt_freq.transmute_rows(**mt_freq.explode_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to hail table\n",
    "ht = mt_freq.rows()\n",
    "\n",
    "ht.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out intergenic variants\n",
    "ht= ht.filter(ht.consequence != 'intergenic_variant')\n",
    "\n",
    "## keep the columns\n",
    "\n",
    "ht = ht.select(\n",
    "    variant_id = ht.variant_id,\n",
    "    dataset = ht.dataset,\n",
    "    ancestry = ht.ancestry,\n",
    "    ac_case = ht.case.AC,\n",
    "    an_case = ht.case.AN,\n",
    "    af_case = ht.case.AF\n",
    ")\n",
    "\n",
    "ht.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out\n",
    "ht.write(BROWSER_VARIANT_RESULTS_TABLE, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.import_vcf(vcf_path,force_bgz=True,\n",
    "                   reference_genome='GRCh38')\n",
    "\n",
    "\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read meta\n",
    "\n",
    "meta = hl.import_table(f'{bucket}/wgs_r10/r10_hail_sample_meta_table.txt',\n",
    "key='s',\n",
    "impute=True)\n",
    "\n",
    "meta.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique ancestry\n",
    "wgs_labels= meta.pop.collect()\n",
    "wgs_ancestry = list(dict.fromkeys(wgs_labels))\n",
    "wgs_ancestry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep variant annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = hl.import_table(annotation_table,missing='\"\"')\n",
    "ht.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace vep synonymous %3D\n",
    "ht = ht.annotate(hgvsp = ht.hgvsp.replace(\"%3D\", \"=\"))\n",
    "ht = ht.annotate(variant_id = ht.variant_id.replace(\"_\", \":\"))\n",
    "# change cadd to float64 \n",
    "ht = ht.annotate(cadd = hl.float(ht.cadd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse locus and alleles \n",
    "ht = ht.key_by(**hl.parse_variant(ht.variant_id,reference_genome='GRCh38'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out \n",
    "ht.write(f'{out_path}/browser_variant_annotation_table.ht', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep freq table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(**meta[mt.s])\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_stats_expression = []\n",
    "\n",
    "for group in wgs_ancestry:\n",
    "    call_stats_expression.append(\n",
    "        hl.struct(ancestry=group,\n",
    "                  dataset= 'WGS',\n",
    "                  case=hl.agg.filter(\n",
    "                        (mt.pop==group) & (mt.pheno=='Case') & (mt.keep==1), \n",
    "                        hl.agg.call_stats(mt.GT, mt.alleles)), \n",
    "                  other=hl.agg.filter(\n",
    "                        (mt.pop==group) & (mt.pheno=='Other') & (mt.keep==1), \n",
    "                        hl.agg.call_stats(mt.GT, mt.alleles)), \n",
    "                  ctrl=hl.agg.filter(\n",
    "                        (mt.pop==group) & (mt.pheno=='Control') & (mt.keep==1), \n",
    "                        hl.agg.call_stats(mt.GT, mt.alleles)))\n",
    ")\n",
    "    \n",
    "wgs_mt_freq = mt.annotate_rows(explode_data=call_stats_expression)\n",
    "\n",
    "# to explode\n",
    "wgs_mt_freq = wgs_mt_freq.explode_rows('explode_data')\n",
    "wgs_mt_freq = wgs_mt_freq.transmute_rows(**wgs_mt_freq.explode_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to hail table\n",
    "wgs_ht = wgs_mt_freq.rows()\n",
    "wgs_ht = wgs_ht.annotate(rsid = wgs_ht.rsid.replace(\"_\", \":\"))\n",
    "wgs_ht = wgs_ht.rename({'rsid' : 'variant_id'})\n",
    "wgs_ht = wgs_ht.drop('info', 'qual', 'filters')\n",
    "\n",
    "wgs_ht = wgs_ht.select(\n",
    "    variant_id = wgs_ht.variant_id,\n",
    "    dataset = wgs_ht.dataset,\n",
    "    ancestry = wgs_ht.ancestry,\n",
    "    ac_case = wgs_ht.case.AC,\n",
    "    an_case = wgs_ht.case.AN,\n",
    "    af_case = wgs_ht.case.AF,\n",
    "    ac_ctrl = wgs_ht.ctrl.AC,\n",
    "    an_ctrl = wgs_ht.ctrl.AN,\n",
    "    af_ctrl = wgs_ht.ctrl.AF,\n",
    "    ac_other = wgs_ht.other.AC,\n",
    "    an_other = wgs_ht.other.AN,\n",
    "    af_other = wgs_ht.other.AF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out\n",
    "\n",
    "wgs_ht.write(BROWSER_VARIANT_RESULTS_TABLE, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
